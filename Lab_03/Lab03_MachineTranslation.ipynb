{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b13bce",
   "metadata": {},
   "source": [
    "# # **Deep Learning Lab 3: Machine Translation**\n",
    "**Author**: BSChen (313510156)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eea4f8-2ce0-4b9b-a4ee-623f451b83b7",
   "metadata": {},
   "source": [
    "# (1) Task description\n",
    "- Translate text from Chinese to English.\n",
    "- Main goal: Get familiar with transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6cc633-1f74-475c-a748-d372a7330332",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702d9c8d-9bc2-4bbb-8251-3c861b90bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bschen/anaconda3/envs/general/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from tqdm import tqdm  # added by myself\n",
    "\n",
    "from utils import *\n",
    "from network import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e415f246-3192-454a-94c7-55681071539a",
   "metadata": {},
   "source": [
    "## Fix random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a05b8e-a4a1-4f56-b2be-7f2c36210ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(29)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28bb849a-a87a-462d-ac8b-4dacb1183c9f",
   "metadata": {},
   "source": [
    "# (2) Data Processing\n",
    "- Original dataset is [Tatoeba](https://tatoeba.org/zh-cn/) and [XDailyDialog](https://github.com/liuzeming01/XDailyDialog)\n",
    "- We select 50000 English-Chinese sentence pairs for translation task\n",
    "\n",
    "- Args:\n",
    "  - BATCH_SIZE  (You can modify)\n",
    "  - data_dir: the path to the given training translation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379f6d70-9e58-4c43-a739-45da13f2738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./translation_train_data.json\"\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fdb5b1-fb5d-4f26-97a1-b19dea9c9254",
   "metadata": {},
   "source": [
    "## Show the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf7de47d-cf72-4915-b700-31f45ffe14d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm Susan Greene.</td>\n",
       "      <td>我是蘇珊格林。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You don't have to take an examination.</td>\n",
       "      <td>你不需要考试。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't leave.</td>\n",
       "      <td>我走不了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A cold beer would hit the spot!</td>\n",
       "      <td>来杯冰啤酒就太棒了!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let's start!</td>\n",
       "      <td>讓我們開始吧。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Just buy a cask of wine. Have you bought ice yet?</td>\n",
       "      <td>买一桶酒就行了。你买冰块了吗?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>OK. No problem.</td>\n",
       "      <td>好的,没问题。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I'm not really in the mood for Italian, actual...</td>\n",
       "      <td>实际上,我不太喜欢意大利菜。我想吃点辣的。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>It's OK. It seems we have a lot in common.</td>\n",
       "      <td>还行吧。看来我们有很多共同点。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>What? You've got to be kidding me!</td>\n",
       "      <td>什么?开什么玩笑!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 English  \\\n",
       "0                                      I'm Susan Greene.   \n",
       "1                 You don't have to take an examination.   \n",
       "2                                         I can't leave.   \n",
       "3                        A cold beer would hit the spot!   \n",
       "4                                           Let's start!   \n",
       "...                                                  ...   \n",
       "49995  Just buy a cask of wine. Have you bought ice yet?   \n",
       "49996                                    OK. No problem.   \n",
       "49997  I'm not really in the mood for Italian, actual...   \n",
       "49998         It's OK. It seems we have a lot in common.   \n",
       "49999                 What? You've got to be kidding me!   \n",
       "\n",
       "                     Chinese  \n",
       "0                    我是蘇珊格林。  \n",
       "1                    你不需要考试。  \n",
       "2                      我走不了。  \n",
       "3                 来杯冰啤酒就太棒了!  \n",
       "4                    讓我們開始吧。  \n",
       "...                      ...  \n",
       "49995        买一桶酒就行了。你买冰块了吗?  \n",
       "49996                好的,没问题。  \n",
       "49997  实际上,我不太喜欢意大利菜。我想吃点辣的。  \n",
       "49998        还行吧。看来我们有很多共同点。  \n",
       "49999              什么?开什么玩笑!  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation_raw_data = pd.read_json(data_dir)\n",
    "display(translation_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87a32c-a292-4fe5-b8c5-9da3f429a23f",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "- Tokenizer: BertTokenizer\n",
    "  - encode: convert text to token ID\n",
    "  - decode: convert token ID back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5db174-7cfd-4680-ad97-daba893322ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tokenizer_english()\n",
    "tokenizer_cn = tokenizer_chinese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12bd1f4-8fd0-4014-be51-8935cff740d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokenize length: 128\n"
     ]
    }
   ],
   "source": [
    "english_seqs = translation_raw_data[\"English\"].apply(lambda x: tokenizer_en.encode(x, add_special_tokens=True, padding=False))\n",
    "chinese_seqs = translation_raw_data[\"Chinese\"].apply(lambda x: tokenizer_cn.encode(x, add_special_tokens=True, padding=False))\n",
    "\n",
    "MAX_TOKENIZE_LENGTH = max(english_seqs.str.len().max(), chinese_seqs.str.len().max()) # longest string\n",
    "MAX_TOKENIZE_LENGTH = pow(2, math.ceil(math.log(MAX_TOKENIZE_LENGTH) / math.log(2)))  # closest upper to the power of 2\n",
    "\n",
    "print(\"Max tokenize length:\", MAX_TOKENIZE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b85b6c-152a-4883-9265-41efb22f9653",
   "metadata": {},
   "source": [
    "## Add paddings\n",
    "- make all the sentences the same length by inserting token ID = PAD_IDX at the back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3169cc-328f-4f41-8905-951a6282edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding\n",
    "def add_padding(token_list: list, max_length: int) -> list:\n",
    "    if len(token_list) < max_length:\n",
    "        padding_length = max_length - len(token_list)\n",
    "        token_list = token_list + [PAD_IDX] * padding_length\n",
    "    else:\n",
    "        token_list = token_list[:max_length]  # Trim to MAX_LENGTH if longer\n",
    "    return token_list\n",
    "\n",
    "chinese_seqs = chinese_seqs.apply(lambda x: add_padding(x, MAX_TOKENIZE_LENGTH))\n",
    "english_seqs = english_seqs.apply(lambda x: add_padding(x, MAX_TOKENIZE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ea75e9-8d80-4735-a7c7-7bc476eeb4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Chinese tokenized data =====\n",
      "[101, 2769, 3221, 5979, 4396, 3419, 3360, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "===== English tokenized data =====\n",
      "[101, 146, 112, 182, 5640, 10983, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Check the padding result\n",
    "print(\"===== Chinese tokenized data =====\")\n",
    "print(chinese_seqs.iloc[0])\n",
    "\n",
    "print(\"===== English tokenized data =====\")\n",
    "print(english_seqs.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e757b-45d9-4be7-b852-4fcfef6de1cf",
   "metadata": {},
   "source": [
    "## Datalodader\n",
    "- Split dataset into training dataset(90%) and validation dataset(10%). You can modify the traning/validation ratio\n",
    "- Create dataloader to iterate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3beb8a-ff48-46bd-9d1f-388580971d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 47500\n",
      "valid size: 2500\n"
     ]
    }
   ],
   "source": [
    "data_size  = len(translation_raw_data)\n",
    "train_size = int(0.95 * data_size)\n",
    "valid_size = data_size - train_size\n",
    "print(\"train size:\", train_size)\n",
    "print(\"valid size:\", valid_size)\n",
    "\n",
    "en_train_data = []\n",
    "cn_train_data = []\n",
    "en_valid_data = []\n",
    "cn_valid_data = []\n",
    "\n",
    "for i in range(data_size):\n",
    "    if (i < train_size):\n",
    "        en_train_data.append(torch.Tensor(english_seqs.iloc[i]))\n",
    "        cn_train_data.append(torch.Tensor(chinese_seqs.iloc[i]))\n",
    "    else:\n",
    "        en_valid_data.append(torch.Tensor(english_seqs.iloc[i]))\n",
    "        cn_valid_data.append(torch.Tensor(chinese_seqs.iloc[i]))\n",
    "\n",
    "class TextTranslationDataset(Dataset): \n",
    "    def __init__(self, src, dst, augment_prob=0):\n",
    "        self.src_list = src\n",
    "        self.dst_list = dst\n",
    "        self.augment_prob = augment_prob\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.src_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if random.random() < self.augment_prob and self.src_list[idx].shape[0] > 7:\n",
    "            # Random dropout\n",
    "            drop_num = random.randint(1, self.src_list[idx].shape[0] - 1)\n",
    "            src = self.src_list[idx].clone()\n",
    "            src[drop_num] = PAD_IDX\n",
    "        else:\n",
    "            src = self.src_list[idx]\n",
    "        return src, self.dst_list[idx]\n",
    "\n",
    "cn_to_en_train_set = TextTranslationDataset(cn_train_data, en_train_data, augment_prob=0.3)\n",
    "cn_to_en_valid_set = TextTranslationDataset(cn_valid_data, en_valid_data)\n",
    "\n",
    "cn_to_en_train_loader = DataLoader(cn_to_en_train_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "cn_to_en_valid_loader = DataLoader(cn_to_en_valid_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03160db-a2ab-49a2-a538-344a8f27c89c",
   "metadata": {},
   "source": [
    "# (3) Model\n",
    "- **TO-DO**: Finish the model in \"network.py\"\n",
    "    - You can first write code here for convenience, but note that <span style='color:red'>**TA will test your model using model definition in \"network.py\"**</span><p>\n",
    "- Base transformer layers in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "    - TransformerEncoderLayer:\n",
    "    - TransformerDecoderLayer:\n",
    "- Positional encoding and input embedding\n",
    "- Note that you may need masks when implementing attention mechanism\n",
    "    - Padding mask: prevent input from attending to padding tokens\n",
    "    - Causal mask: prevent decoder input from attending to future input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ecfe90-37fa-4735-8265-2dcada1d819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameter size of model is 24759.876 k\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "param_model = sum(p.numel() for p in model.parameters())\n",
    "print (f\"The parameter size of model is {param_model / 1000} k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8086b4f-57b4-4d8a-812b-03b50319a368",
   "metadata": {},
   "source": [
    "# (4) Training\n",
    "- You can change the training setting by yourself including\n",
    "  - Number of epoch\n",
    "  - Optimizer\n",
    "  - Learning rate\n",
    "  - Learning rate scheduler\n",
    "  - etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409a5008-c773-484a-89e2-3670cc872f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "LEARNING_RATE = 1e-2\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, betas=(0.9, 0.98), eps=1e-9)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=1e-5)\n",
    "# scheduler = None\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.7, patience=5, min_lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9aa45c-886a-48bd-9f3b-a89a1d3c91aa",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad8b1aaf-97b4-41f4-b127-78a988cf22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_dataloader: DataLoader\n",
    "    ):\n",
    "    # Initialization\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_dataloader):\n",
    "        # src, tgt shape: (batch_size, seq_length)\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "\n",
    "        logits = model(src, tgt_input)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_output.reshape(-1).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module, val_dataloader: DataLoader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    score = 0\n",
    "\n",
    "    for src, tgt in tqdm(val_dataloader):\n",
    "        # src, tgt shape: (batch_size, seq_length)\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        \n",
    "        logits = model(src, tgt_input)\n",
    "        _, tgt_predict = torch.max(logits, dim=-1)\n",
    "        score_batch = BLEU_batch(tgt_predict, tgt_output, tokenizer_en)\n",
    "\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_output.reshape(-1).long())\n",
    "        losses += loss.item()\n",
    "        score += score_batch\n",
    "\n",
    "    return (losses / len(list(val_dataloader))), (score / len(list(val_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3012a-bd6f-4ca1-9ff5-ea1162920e0e",
   "metadata": {},
   "source": [
    "## Start training\n",
    "- MODEL_SAVE_PATH: path for storing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2640ed86-192a-4a85-82da-46347fb765fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"./model.ckpt\"\n",
    "LOG_FILE_PATH = \"log.csv\"\n",
    "SAVE_TOLERANCE = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ebf57b-de88-4de2-a18b-de519d72560d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Model training on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 144.07it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 113.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 4.121, Val loss: 3.724, Val Acc: 0.227, Epoch time = 41.370s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 144.06it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 112.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 3.179, Val loss: 3.250, Val Acc: 0.301, Epoch time = 41.363s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 144.06it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 111.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 2.738, Val loss: 3.052, Val Acc: 0.338, Epoch time = 41.485s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.79it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 111.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 2.458, Val loss: 2.884, Val Acc: 0.357, Epoch time = 41.439s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.79it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 111.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 2.253, Val loss: 2.788, Val Acc: 0.378, Epoch time = 41.440s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.77it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 111.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 2.089, Val loss: 2.736, Val Acc: 0.392, Epoch time = 41.443s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.84it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 111.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 1.956, Val loss: 2.686, Val Acc: 0.401, Epoch time = 41.425s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.47it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 1.840, Val loss: 2.647, Val Acc: 0.405, Epoch time = 41.532s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.82it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 111.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 1.741, Val loss: 2.642, Val Acc: 0.406, Epoch time = 41.432s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.68it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 1.656, Val loss: 2.627, Val Acc: 0.412, Epoch time = 41.472s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.64it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 1.580, Val loss: 2.646, Val Acc: 0.418, Epoch time = 41.485s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.62it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 1.508, Val loss: 2.673, Val Acc: 0.419, Epoch time = 41.488s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.74it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 1.449, Val loss: 2.685, Val Acc: 0.422, Epoch time = 41.584s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.79it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 1.392, Val loss: 2.708, Val Acc: 0.422, Epoch time = 41.437s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.75it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 1.340, Val loss: 2.722, Val Acc: 0.423, Epoch time = 41.452s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.71it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 1.291, Val loss: 2.743, Val Acc: 0.430, Epoch time = 41.464s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.74it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 1.120, Val loss: 2.694, Val Acc: 0.431, Epoch time = 41.454s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.74it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 1.054, Val loss: 2.707, Val Acc: 0.440, Epoch time = 41.454s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.84it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 1.020, Val loss: 2.732, Val Acc: 0.442, Epoch time = 41.427s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.73it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 0.989, Val loss: 2.751, Val Acc: 0.440, Epoch time = 41.458s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.84it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train loss: 0.960, Val loss: 2.775, Val Acc: 0.438, Epoch time = 41.553s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.89it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train loss: 0.937, Val loss: 2.815, Val Acc: 0.436, Epoch time = 41.410s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 144.04it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train loss: 0.823, Val loss: 2.797, Val Acc: 0.445, Epoch time = 41.366s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.48it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train loss: 0.783, Val loss: 2.812, Val Acc: 0.447, Epoch time = 41.529s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.79it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train loss: 0.758, Val loss: 2.840, Val Acc: 0.447, Epoch time = 41.441s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.55it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train loss: 0.737, Val loss: 2.877, Val Acc: 0.443, Epoch time = 41.510s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.77it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train loss: 0.718, Val loss: 2.913, Val Acc: 0.446, Epoch time = 41.444s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.81it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train loss: 0.699, Val loss: 2.897, Val Acc: 0.447, Epoch time = 41.435s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.78it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train loss: 0.628, Val loss: 2.899, Val Acc: 0.451, Epoch time = 41.444s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.65it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train loss: 0.601, Val loss: 2.929, Val Acc: 0.452, Epoch time = 41.607s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.88it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train loss: 0.587, Val loss: 2.967, Val Acc: 0.453, Epoch time = 41.414s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.37it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train loss: 0.570, Val loss: 3.004, Val Acc: 0.453, Epoch time = 41.562s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.84it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train loss: 0.556, Val loss: 2.985, Val Acc: 0.448, Epoch time = 41.427s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.62it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train loss: 0.546, Val loss: 3.022, Val Acc: 0.453, Epoch time = 41.485s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.70it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train loss: 0.498, Val loss: 3.025, Val Acc: 0.457, Epoch time = 41.464s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.85it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train loss: 0.481, Val loss: 3.039, Val Acc: 0.455, Epoch time = 41.424s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.88it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train loss: 0.470, Val loss: 3.069, Val Acc: 0.455, Epoch time = 41.413s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.94it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train loss: 0.458, Val loss: 3.100, Val Acc: 0.453, Epoch time = 41.394s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.70it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train loss: 0.450, Val loss: 3.078, Val Acc: 0.456, Epoch time = 41.595s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.88it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train loss: 0.443, Val loss: 3.109, Val Acc: 0.452, Epoch time = 41.413s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.86it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train loss: 0.411, Val loss: 3.101, Val Acc: 0.457, Epoch time = 41.418s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.52it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train loss: 0.399, Val loss: 3.143, Val Acc: 0.453, Epoch time = 41.517s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 144.01it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train loss: 0.392, Val loss: 3.167, Val Acc: 0.457, Epoch time = 41.374s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.69it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train loss: 0.386, Val loss: 3.162, Val Acc: 0.456, Epoch time = 41.466s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.84it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train loss: 0.378, Val loss: 3.168, Val Acc: 0.457, Epoch time = 41.422s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.75it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train loss: 0.374, Val loss: 3.180, Val Acc: 0.455, Epoch time = 41.450s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 144.05it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train loss: 0.353, Val loss: 3.197, Val Acc: 0.459, Epoch time = 41.366s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.90it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train loss: 0.347, Val loss: 3.225, Val Acc: 0.457, Epoch time = 41.538s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.91it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train loss: 0.338, Val loss: 3.224, Val Acc: 0.455, Epoch time = 41.404s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.91it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train loss: 0.335, Val loss: 3.249, Val Acc: 0.458, Epoch time = 41.402s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.71it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Train loss: 0.331, Val loss: 3.240, Val Acc: 0.458, Epoch time = 41.459s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.81it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, Train loss: 0.325, Val loss: 3.233, Val Acc: 0.456, Epoch time = 41.433s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.91it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, Train loss: 0.314, Val loss: 3.257, Val Acc: 0.457, Epoch time = 41.402s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.86it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, Train loss: 0.307, Val loss: 3.272, Val Acc: 0.457, Epoch time = 41.418s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 144.04it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, Train loss: 0.304, Val loss: 3.279, Val Acc: 0.458, Epoch time = 41.365s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.70it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Train loss: 0.300, Val loss: 3.292, Val Acc: 0.457, Epoch time = 41.464s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.79it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57, Train loss: 0.297, Val loss: 3.313, Val Acc: 0.457, Epoch time = 41.437s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.67it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, Train loss: 0.293, Val loss: 3.303, Val Acc: 0.457, Epoch time = 41.601s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.75it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59, Train loss: 0.287, Val loss: 3.291, Val Acc: 0.458, Epoch time = 41.450s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 144.06it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Train loss: 0.284, Val loss: 3.320, Val Acc: 0.459, Epoch time = 41.361s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.89it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61, Train loss: 0.280, Val loss: 3.305, Val Acc: 0.459, Epoch time = 41.410s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.84it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, Train loss: 0.277, Val loss: 3.299, Val Acc: 0.458, Epoch time = 41.427s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.63it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63, Train loss: 0.275, Val loss: 3.333, Val Acc: 0.460, Epoch time = 41.484s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.77it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, Train loss: 0.273, Val loss: 3.324, Val Acc: 0.458, Epoch time = 41.446s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.81it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, Train loss: 0.269, Val loss: 3.324, Val Acc: 0.460, Epoch time = 41.435s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.62it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 105.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Train loss: 0.266, Val loss: 3.330, Val Acc: 0.460, Epoch time = 41.488s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.73it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67, Train loss: 0.264, Val loss: 3.312, Val Acc: 0.459, Epoch time = 41.456s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.86it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, Train loss: 0.260, Val loss: 3.365, Val Acc: 0.458, Epoch time = 41.417s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.78it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Train loss: 0.259, Val loss: 3.355, Val Acc: 0.460, Epoch time = 41.441s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.89it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, Train loss: 0.259, Val loss: 3.345, Val Acc: 0.459, Epoch time = 41.409s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.65it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71, Train loss: 0.257, Val loss: 3.362, Val Acc: 0.460, Epoch time = 41.477s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.70it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, Train loss: 0.254, Val loss: 3.349, Val Acc: 0.458, Epoch time = 41.465s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:44<00:00, 134.35it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 107.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, Train loss: 0.252, Val loss: 3.355, Val Acc: 0.459, Epoch time = 44.351s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.77it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 109.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, Train loss: 0.252, Val loss: 3.358, Val Acc: 0.458, Epoch time = 41.447s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.49it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, Train loss: 0.249, Val loss: 3.357, Val Acc: 0.458, Epoch time = 41.658s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.61it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, Train loss: 0.248, Val loss: 3.384, Val Acc: 0.458, Epoch time = 41.490s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.67it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, Train loss: 0.248, Val loss: 3.383, Val Acc: 0.460, Epoch time = 41.475s\n",
      "(model saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.83it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, Train loss: 0.245, Val loss: 3.381, Val Acc: 0.459, Epoch time = 41.427s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.18it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79, Train loss: 0.244, Val loss: 3.384, Val Acc: 0.460, Epoch time = 41.614s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [00:41<00:00, 143.57it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 110.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Train loss: 0.243, Val loss: 3.380, Val Acc: 0.459, Epoch time = 41.502s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")\n",
    "print(f\"Model training on device: {DEVICE}\")\n",
    "\n",
    "# Initialization\n",
    "model = model.to(DEVICE)\n",
    "with open(LOG_FILE_PATH, 'w') as log_file:\n",
    "    log_file.write(\"Epoch, Train Loss, Val Loss, Val Acc, Epoch Time\\n\")\n",
    "\n",
    "best_acc = 0\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(\n",
    "        # Main translation model\n",
    "        model,\n",
    "        optimizer,\n",
    "        cn_to_en_train_loader\n",
    "    )\n",
    "    end_time = timer()\n",
    "    val_loss, val_acc = evaluate(model, cn_to_en_valid_loader)\n",
    "\n",
    "    # Log the results\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    with open(LOG_FILE_PATH, 'a') as log_file:\n",
    "        log_file.write(f\"{epoch}, {train_loss:.3f}, {val_loss:.3f}, {val_acc:.3f}, {(end_time - start_time):.3f}\\n\")\n",
    "\n",
    "    # Save the best model so far.\n",
    "    if val_acc > best_acc - SAVE_TOLERANCE:\n",
    "        best_acc = val_acc if val_acc > best_acc else best_acc\n",
    "        best_state_dict = model.state_dict()\n",
    "        torch.save(best_state_dict, MODEL_SAVE_PATH)\n",
    "        print(\"(model saved)\")\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1c0699-b80e-40eb-b7b0-0906b09784c0",
   "metadata": {},
   "source": [
    "# (5) Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e06c7d-8ba4-4761-86f2-b7db7ed6b3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bschen/anaconda3/envs/general/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72716630-5f87-41a4-aece-78d8315e7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tokenizer_english()\n",
    "tokenizer_cn = tokenizer_chinese()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41175b6f-7fb5-48d2-bc7c-3b9cff764d17",
   "metadata": {},
   "source": [
    "## Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3198b31-30a3-46aa-bb02-22913de7909e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(MODEL_PATH=\"model.ckpt\")\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560658f5-a89e-464b-8e08-8955dafc68c0",
   "metadata": {},
   "source": [
    "## Translation testing\n",
    " - **TO-DO**: Finish the \"translate\" function in \"network.py\"\n",
    "   - You can first write code here for convenience, but note that <span style='color:red'>**TA will test your model using \"translate\" function in \"network.py\"**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44dc1b7-38be-4692-9981-dea8845dd9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input          : 你好，欢迎来到中国。\n",
      "Prediction     : You are a good reputation for China.\n",
      "Ground truth   : Hello, welcome to China.\n",
      "Bleu Score (1-gram):  0.1428571492433548\n",
      "Bleu Score (2-gram):  0.0\n",
      "Bleu Score (3-gram):  0.0\n",
      "Bleu Score (4-gram):  0.0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"你好，欢迎来到中国。\"\n",
    "ground_truth = 'Hello, welcome to China.'\n",
    "predicted = translate(model, sentence, tokenizer_cn, tokenizer_en)\n",
    "\n",
    "print(f'{\"Input\":15s}: {sentence}')\n",
    "print(f'{\"Prediction\":15s}: {predicted}')\n",
    "print(f'{\"Ground truth\":15s}: {ground_truth}')\n",
    "print(\"Bleu Score (1-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 1).item())\n",
    "print(\"Bleu Score (2-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 2).item())\n",
    "print(\"Bleu Score (3-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 3).item())\n",
    "print(\"Bleu Score (4-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 4).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7ed8be-73ba-441c-8490-3ad93ead9f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input          : 她知道您的電話號碼嗎?\n",
      "Prediction     : Does she know your telephone number?\n",
      "Ground truth   : Does she know your telephone number?\n",
      "Bleu Score (1-gram):  1.0\n",
      "Bleu Score (2-gram):  1.0\n",
      "Bleu Score (3-gram):  1.0\n",
      "Bleu Score (4-gram):  1.0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"她知道您的電話號碼嗎?\"\n",
    "ground_truth = 'Does she know your telephone number?'\n",
    "predicted = translate(model, sentence, tokenizer_cn, tokenizer_en)\n",
    "\n",
    "print(f'{\"Input\":15s}: {sentence}')\n",
    "print(f'{\"Prediction\":15s}: {predicted}')\n",
    "print(f'{\"Ground truth\":15s}: {ground_truth}')\n",
    "print(\"Bleu Score (1-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 1).item())\n",
    "print(\"Bleu Score (2-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 2).item())\n",
    "print(\"Bleu Score (3-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 3).item())\n",
    "print(\"Bleu Score (4-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 4).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12708039-9697-4918-b7f7-1dfa09cff76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : 你现在在哪里工作?\n",
      "Prediction     : Where do you work right now?\n",
      "Ground truth   : Where do you work now?\n",
      "Bleu Score (1-gram):  0.8333333134651184\n",
      "Bleu Score (2-gram):  0.7071067690849304\n",
      "Bleu Score (3-gram):  0.6299605369567871\n",
      "Bleu Score (4-gram):  0.5372849702835083\n"
     ]
    }
   ],
   "source": [
    "sentence = \"你现在在哪里工作?\"\n",
    "ground_truth = 'Where do you work now?'\n",
    "predicted = translate(model, sentence, tokenizer_cn, tokenizer_en)\n",
    "\n",
    "print(f'{\"Input\":15s}: {sentence}')\n",
    "print(f'{\"Prediction\":15s}: {predicted}')\n",
    "print(f'{\"Ground truth\":15s}: {ground_truth}')\n",
    "print(\"Bleu Score (1-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 1).item())\n",
    "print(\"Bleu Score (2-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 2).item())\n",
    "print(\"Bleu Score (3-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 3).item())\n",
    "print(\"Bleu Score (4-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 4).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d59d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input          : 歡迎來到台灣。\n",
      "Prediction     : Welcome to Taiwan.\n",
      "Ground truth   : Welcome to Taiwan.\n",
      "Bleu Score (1-gram):  1.0\n",
      "Bleu Score (2-gram):  1.0\n",
      "Bleu Score (3-gram):  1.0\n",
      "Bleu Score (4-gram):  0.0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"歡迎來到台灣。\"\n",
    "ground_truth = \"Welcome to Taiwan.\"\n",
    "predicted = translate(model, sentence, tokenizer_cn, tokenizer_en)\n",
    "\n",
    "print(f'{\"Input\":15s}: {sentence}')\n",
    "print(f'{\"Prediction\":15s}: {predicted}')\n",
    "print(f'{\"Ground truth\":15s}: {ground_truth}')\n",
    "print(\"Bleu Score (1-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 1).item())\n",
    "print(\"Bleu Score (2-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 2).item())\n",
    "print(\"Bleu Score (3-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 3).item())\n",
    "print(\"Bleu Score (4-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 4).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b856953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input          : 你好，歡迎來到台灣。\n",
      "Prediction     : You are competent studying in Taiwan.\n",
      "Ground truth   : Hello, welcome to Taiwan.\n",
      "Bleu Score (1-gram):  0.1666666567325592\n",
      "Bleu Score (2-gram):  0.0\n",
      "Bleu Score (3-gram):  0.0\n",
      "Bleu Score (4-gram):  0.0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"你好，歡迎來到台灣。\"\n",
    "ground_truth = \"Hello, welcome to Taiwan.\"\n",
    "predicted = translate(model, sentence, tokenizer_cn, tokenizer_en)\n",
    "\n",
    "print(f'{\"Input\":15s}: {sentence}')\n",
    "print(f'{\"Prediction\":15s}: {predicted}')\n",
    "print(f'{\"Ground truth\":15s}: {ground_truth}')\n",
    "print(\"Bleu Score (1-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 1).item())\n",
    "print(\"Bleu Score (2-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 2).item())\n",
    "print(\"Bleu Score (3-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 3).item())\n",
    "print(\"Bleu Score (4-gram): \", bleu_score_func(predicted.lower(), ground_truth.lower(), 4).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
